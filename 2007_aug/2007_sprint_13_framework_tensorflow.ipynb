{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFLowによって2値分類を行うサンプルコードを載せました。今回はこれをベースにして進めます。\n",
    "\n",
    "\n",
    "tf.kerasやtf.estimatorなどの高レベルAPIは使用していません。低レベルなところから見ていくことにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】スクラッチを振り返る\n",
    "ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n",
    "\n",
    "\n",
    "（例）\n",
    "\n",
    "\n",
    "重みを初期化する必要があった\n",
    "\n",
    "エポックのループが必要だった\n",
    "\n",
    "それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。\n",
    "\n",
    "\n",
    "### データセットの用意\n",
    "以前から使用しているIrisデータセットを使用します。以下のサンプルコードではIris.csvが同じ階層にある想定です。\n",
    "\n",
    "\n",
    "[Iris Species](https://www.kaggle.com/uciml/iris/data)\n",
    "\n",
    "\n",
    "目的変数はSpeciesですが、3種類ある中から以下の2種類のみを取り出して使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris-versicolor\n",
    "Iris-virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【解答】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ディープラーニングの実装に必要だったもの__\n",
    "\n",
    "* 活性化関数\n",
    "* 誤差関数\n",
    "* 全結合層\n",
    "* エポックとミニバッチ\n",
    "* オプティマイザ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】スクラッチとTensorFlowの対応を考える\n",
    "以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n",
    "\n",
    "\n",
    "それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。\n",
    "\n",
    "\n",
    "### 《サンプルコード》\n",
    "\n",
    "\n",
    "＊バージョン1.5から1.14の間で動作を確認済みです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kouta/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 0, loss : 20.0999, val_loss : 48.3906, acc : 0.750, val_acc : 0.375\n",
      "Epoch 1, loss : 35.3637, val_loss : 17.8348, acc : 0.250, val_acc : 0.625\n",
      "Epoch 2, loss : 4.6430, val_loss : 12.4097, acc : 0.750, val_acc : 0.375\n",
      "Epoch 3, loss : 0.4239, val_loss : 3.4644, acc : 0.750, val_acc : 0.500\n",
      "Epoch 4, loss : 1.2481, val_loss : 3.8557, acc : 0.750, val_acc : 0.750\n",
      "Epoch 5, loss : 0.0130, val_loss : 3.3686, acc : 1.000, val_acc : 0.625\n",
      "Epoch 6, loss : 0.0354, val_loss : 3.1664, acc : 1.000, val_acc : 0.750\n",
      "Epoch 7, loss : 0.0000, val_loss : 1.7503, acc : 1.000, val_acc : 0.812\n",
      "Epoch 8, loss : 0.0270, val_loss : 4.1209, acc : 1.000, val_acc : 0.750\n",
      "Epoch 9, loss : 0.0189, val_loss : 4.2885, acc : 1.000, val_acc : 0.625\n",
      "test_acc : 0.750\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "# データセットの読み込み\n",
    "dataset_path =\"datasets_19_420_Iris.csv\" #csv読み込み\n",
    "df = pd.read_csv(dataset_path) # dataframe化\n",
    "\n",
    "# データフレームから条件抽出\n",
    "# Xとyを作成\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "# ついでにyを二次元に\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ミニバッチクラス\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]\n",
    "    \n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01 # 学習率\n",
    "batch_size = 10 # バッチサイズ\n",
    "num_epochs = 10 # エポック数\n",
    "n_hidden1 = 50 # 隠れ層の出力サイズ\n",
    "n_hidden2 = 100 # 隠れ層の出力サイズ２\n",
    "n_input = X_train.shape[1] # インプットの列数、特徴量数\n",
    "n_samples = X_train.shape[0] # インプットの行数、データ数\n",
    "n_classes = 1 # クラス数？\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "# https://note.nkmk.me/python-tensorflow-constant-variable-placeholder/\n",
    "X = tf.placeholder(\"float\", [None, n_input]) # プレースホルダーはデータが格納される入れ物。データは未定のままグラフを構築し、具体的な値は実行する時に与える。\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ここが計算グラフのところ？ネットワーク作成関数。スクラッチの時で言えばSimpleConvnetあたりか。\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    # 重みとバイアスの宣言\n",
    "    # tf.Variableで変数の宣言。中身はtf.random_normalでランダムに作成。np.random.normalみたいなもんか\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    \n",
    "    # レイヤーイテレータ。tf.matmulは行列積。np.dotみたいなもの。微妙に挙動違うっぽいので要確認。\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output\n",
    "\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "# sigmoid_cross_entropy_with_logitsはシグモイド関数を通してクロスエントロピー誤差を算出する\n",
    "# 中身はz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x)) x=logits, z=labels\n",
    "# ラベルかけるマイナスlog(シグモイド(X)) + (1-ラベル)かけるマイナスlog(1 - シグモイド(X))\n",
    "# 0以下の場合は0を出すので、まとめるとmax(x, 0) - x * z + log(1 + exp(-abs(x)))こうなる\n",
    "# reduce_meanはnp.meanと同じ、axis=Noneだと単一のスカラーが返ってくる\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "# インスタンス化\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# minimize()で呼び出し\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# 推定結果\n",
    "# tf.equalは比較して同じだったらTrue、違えばFalseをarrayで返す\n",
    "# signはサイン波に変換してる、-0.5する意味はよくわかってない\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "# 指標値計算\n",
    "# castはテンソルの型を変更する。np.astypeみたいな感じ？\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化をするインスタンス\n",
    "# This is just a shortcut for `variables_initializer(global_variables())`\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【解答及びメモ】\n",
    "\n",
    "* tensorflowは変数とか先に宣言する。オブジェクト型ではない？\n",
    "* 考えたらC++で動いてるから当たり前か。入り口がpythonで書けるというだけで中身がC++なら、基本はC系統だと思っておいた方が良さそう。\n",
    "\n",
    "\n",
    "__自作CNNとの相関__\n",
    "* 活性化関数　→ レイヤーのイテレータを通している。tf.nn.relu()でやってる、relu部分を変えられる。\n",
    "* 誤差関数　→ tf.nn.sigmoid_cross_entropy_with_logitsで実装\n",
    "* 全結合層　→ イテレータlayerで実装、logitsにネットワーク構造が入ってて、loss_opが走るとフォワードプロパゲーション、train_opで損失関数と勾配更新まで行う。このモデルではAdamOptimizerが使用されてる。\n",
    "* エポックとミニバッチ　→ ここはおんなじ。ミニバッチ関数とエポックは普通にfor文\n",
    "* オプティマイザ　→ インスタンス化してminimize()で呼び出し。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3,他のデータセットへの適用\n",
    "\n",
    "これまで扱ってきた小さなデータセットがいくつかあります。上記サンプルコードを書き換え、これらに対して学習・推定を行うニューラルネットワークを作成してください。\n",
    "\n",
    "\n",
    "* Iris（3種類全ての目的変数を使用）\n",
    "* House Prices\n",
    "\n",
    "どのデータセットもtrain, val, testの3種類に分けて使用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成\n",
    "Irisデータセットのtrain.csvの中で、目的変数Speciesに含まれる3種類全てを分類できるモデルを作成してください。\n",
    "\n",
    "\n",
    "[Iris Species](https://www.kaggle.com/uciml/iris/data)\n",
    "\n",
    "\n",
    "2クラスの分類と3クラス以上の分類の違いを考慮してください。それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。\n",
    "\n",
    "\n",
    "《ヒント》\n",
    "\n",
    "\n",
    "以下の2箇所は2クラス分類特有の処理です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メソッドは以下のように公式ドキュメントを確認してください。\n",
    "\n",
    "\n",
    "[tf.nn.sigmoid_cross_entropy_with_logits  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)\n",
    "\n",
    "\n",
    "[tf.math.sign  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/math/sign)\n",
    "\n",
    "\n",
    "＊tf.signとtf.math.signは同じ働きをします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【解答】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 1.7809, val_loss : 2.5576, acc : 0.667, val_acc : 0.542\n",
      "Epoch 1, loss : 0.7699, val_loss : 2.8283, acc : 0.833, val_acc : 0.750\n",
      "Epoch 2, loss : 0.0000, val_loss : 2.8492, acc : 1.000, val_acc : 0.792\n",
      "Epoch 3, loss : 0.0001, val_loss : 4.7234, acc : 1.000, val_acc : 0.750\n",
      "Epoch 4, loss : 0.5868, val_loss : 8.1870, acc : 0.833, val_acc : 0.667\n",
      "Epoch 5, loss : 0.0001, val_loss : 5.3880, acc : 1.000, val_acc : 0.708\n",
      "Epoch 6, loss : 0.0000, val_loss : 2.2441, acc : 1.000, val_acc : 0.833\n",
      "Epoch 7, loss : 0.0000, val_loss : 1.5002, acc : 1.000, val_acc : 0.917\n",
      "Epoch 8, loss : 0.0000, val_loss : 2.1333, acc : 1.000, val_acc : 0.917\n",
      "Epoch 9, loss : 0.0000, val_loss : 5.2664, acc : 1.000, val_acc : 0.708\n",
      "test_acc : 0.967\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを3値分類する\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "# データセットの読み込み\n",
    "dataset_path =\"datasets_19_420_Iris.csv\" #csv読み込み\n",
    "df = pd.read_csv(dataset_path) # dataframe化\n",
    "\n",
    "# データフレームから条件抽出\n",
    "# Xとyを作成\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "#display(y)\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルをone-hot-vectorに変換\n",
    "# ついでにyを二次元に\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:, np.newaxis])\n",
    "#print(y.shape)\n",
    "#display(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "#print(X_train.shape)\n",
    "\n",
    "# ミニバッチクラス\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]\n",
    "    \n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01 # 学習率\n",
    "batch_size = 10 # バッチサイズ\n",
    "num_epochs = 10 # エポック数\n",
    "n_hidden1 = 50 # 隠れ層の出力サイズ\n",
    "n_hidden2 = 100 # 隠れ層の出力サイズ２\n",
    "n_input = X_train.shape[1] # インプットの列数、特徴量数\n",
    "n_samples = X_train.shape[0] # インプットの行数、データ数\n",
    "n_classes = 3 # クラス数。二値分類で１列で済むなら1で良いけど、one-hotしてるならその分増やす。今回は3。\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "# https://note.nkmk.me/python-tensorflow-constant-variable-placeholder/\n",
    "X = tf.placeholder(\"float\", [None, n_input]) # プレースホルダーはデータが格納される入れ物。データは未定のままグラフを構築し、具体的な値は実行する時に与える。\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "# ここが計算グラフのところ？ネットワーク作成関数。スクラッチの時で言えばSimpleConvnetあたりか。\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    # 重みとバイアスの宣言\n",
    "    # tf.Variableで変数の宣言。中身はtf.random_normalでランダムに作成。np.random.normalみたいなもんか\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1], seed=128)),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2], seed=128)),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes], seed=128))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1], seed=128)),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2], seed=128)),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes], seed=128))\n",
    "    }\n",
    "    \n",
    "    # レイヤーイテレータ。tf.matmulは行列積。np.dotみたいなもの。微妙に挙動違うっぽいので要確認。\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    #print(layer_1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    #print(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    #print(layer_2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    #print(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    #print(layer_output)\n",
    "    return layer_output\n",
    "\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "# sigmoid_cross_entropy_with_logitsはシグモイド関数を通してクロスエントロピー誤差を算出する\n",
    "# 中身はz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x)) x=logits, z=labels\n",
    "# ラベルかけるマイナスlog(シグモイド(X)) + (1-ラベル)かけるマイナスlog(1 - シグモイド(X))\n",
    "# 0以下の場合は0を出すので、まとめるとmax(x, 0) - x * z + log(1 + exp(-abs(x)))こうなる\n",
    "# reduce_meanはnp.meanと同じ、axis=Noneだと単一のスカラーが返ってくる\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法\n",
    "# インスタンス化\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# minimize()で呼び出し\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# 推定結果\n",
    "# tf.equalは比較して同じだったらTrue、違えばFalseをarrayで返す\n",
    "# signはサイン波に変換してる、-0.5する意味はよくわかってない\n",
    "softmax_out = tf.nn.softmax(logits, axis=1)\n",
    "correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(softmax_out, 1))\n",
    "#correct_pred = tf.equal(tf.argmax(Y), tf.argmax(softmax_out))\n",
    "# 指標値計算\n",
    "# castはテンソルの型を変更する。np.astypeみたいな感じ？\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化をするインスタンス\n",
    "# This is just a shortcut for `variables_initializer(global_variables())`\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# ここまでで宣言や初期化が完了、↓でコンパイル。\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            #print(sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            #print(sess.run(loss_op, feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】House Pricesのモデルを作成\n",
    "回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n",
    "\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "\n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n",
    "\n",
    "\n",
    "分類問題と回帰問題の違いを考慮してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【解答】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 1114.7831, val_loss : 6.3026, MSE : 1114.783, val_MSE : 6.303\n",
      "Epoch 1, loss : 30.8781, val_loss : 2.7913, MSE : 30.878, val_MSE : 2.791\n",
      "Epoch 2, loss : 15.9101, val_loss : 1.8899, MSE : 15.910, val_MSE : 1.890\n",
      "Epoch 3, loss : 8.6517, val_loss : 0.7862, MSE : 8.652, val_MSE : 0.786\n",
      "Epoch 4, loss : 7.0297, val_loss : 0.6294, MSE : 7.030, val_MSE : 0.629\n",
      "Epoch 5, loss : 5.0656, val_loss : 0.6221, MSE : 5.066, val_MSE : 0.622\n",
      "Epoch 6, loss : 5.7232, val_loss : 0.4701, MSE : 5.723, val_MSE : 0.470\n",
      "Epoch 7, loss : 5.5089, val_loss : 0.4584, MSE : 5.509, val_MSE : 0.458\n",
      "Epoch 8, loss : 4.2119, val_loss : 0.4082, MSE : 4.212, val_MSE : 0.408\n",
      "Epoch 9, loss : 5.4204, val_loss : 0.6405, MSE : 5.420, val_MSE : 0.641\n",
      "test_MSE : 0.760\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#import random\n",
    "#os.environ['PYTHONHASHSEED'] = \"0\"\n",
    "#np.random.seed(0)\n",
    "#random.seed(0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いHousePriceデータセットを回帰分類する\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"train.csv\" #csv読み込み\n",
    "df = pd.read_csv(dataset_path) # dataframe化\n",
    "\n",
    "# データフレームから条件抽出\n",
    "# Xとyを作成\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df.loc[:,[\"SalePrice\"]]\n",
    "#display(y)\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "#print(y.shape)\n",
    "#print(X.shape)\n",
    "\n",
    "\n",
    "# 特徴量を標準化\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# 目的変数を対数変換\n",
    "y = np.log1p(y)\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "#print(X_train.shape)\n",
    "\n",
    "#plt.scatter(X_test[:,0],y_test)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01 # 学習率\n",
    "batch_size = 10 # バッチサイズ\n",
    "num_epochs = 10 # エポック数\n",
    "n_hidden1 = 50 # 隠れ層の出力サイズ\n",
    "n_hidden2 = 100 # 隠れ層の出力サイズ２\n",
    "n_input = X_train.shape[1] # インプットの列数、特徴量数\n",
    "n_samples = X_train.shape[0] # インプットの行数、データ数\n",
    "n_classes = 1 # クラス数。二値分類で１列で済むなら1で良いけど、one-hotしてるならその分増やす。今回は3。\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "# https://note.nkmk.me/python-tensorflow-constant-variable-placeholder/\n",
    "X = tf.placeholder(\"float\", [None, n_input]) # プレースホルダーはデータが格納される入れ物。データは未定のままグラフを構築し、具体的な値は実行する時に与える。\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# ここが計算グラフのところ？ネットワーク作成関数。スクラッチの時で言えばSimpleConvnetあたりか。\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    # 重みとバイアスの宣言\n",
    "    # tf.Variableで変数の宣言。中身はtf.random_normalでランダムに作成。np.random.normalみたいなもんか\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1], seed=0)),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2], seed=0)),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes], seed=0))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1], seed=0)),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2], seed=0)),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes], seed=0))\n",
    "    }\n",
    "    \n",
    "    # レイヤーイテレータ。tf.matmulは行列積。np.dotみたいなもの。微妙に挙動違うっぽいので要確認。\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    #print(layer_1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    #print(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    #print(layer_2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    #print(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    #print(layer_output)\n",
    "    return layer_output\n",
    "\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "#loss_op = tf.reduce_mean(tf.squared_difference(Y, logits))\n",
    "loss_op = tf.reduce_mean(tf.square(logits - Y))\n",
    "# 最適化手法\n",
    "# インスタンス化\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "#optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "# minimize()で呼び出し\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# 推定結果\n",
    "#correct_pred = logits\n",
    "# 指標値計算\n",
    "# castはテンソルの型を変更する。np.astypeみたいな感じ？\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.squared_difference(Y, logits))\n",
    "\n",
    "# variableの初期化をするインスタンス\n",
    "# This is just a shortcut for `variables_initializer(global_variables())`\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# ここまでで宣言や初期化が完了、↓でコンパイル。\n",
    "\n",
    "\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)    \n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            #print(sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            #print(sess.run(loss_op, feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= batch_size\n",
    "        total_acc /= batch_size\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, MSE : {:.3f}, val_MSE : {:.3f}\".format(epoch, total_loss, val_loss, total_acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_MSE : {:.3f}\".format(test_acc))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】MNISTのモデルを作成\n",
    "ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n",
    "\n",
    "\n",
    "3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n",
    "\n",
    "\n",
    "スクラッチで実装したモデルの再現を目指してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, im_rows, im_cols, im_color)\n",
    "X_train = X_train.astype('float64') / 255\n",
    "X_test = X_test.reshape(-1, im_rows, im_cols, im_color)\n",
    "X_test = X_test.astype('float64') / 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "print(X_train[0].dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# ラベルをone-hot-vectorに変換\n",
    "# ついでにyを二次元に\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.fit_transform(y_test[:, np.newaxis])\n",
    "print(y_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【解答】自作関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd788a14410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd788a14410>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd788a14410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd788a14410>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Epoch 0, loss : 0.7174, val_loss : 0.7785, acc : 0.800, val_acc : 0.734\n",
      "Epoch 1, loss : 0.0861, val_loss : 0.3341, acc : 1.000, val_acc : 0.915\n",
      "Epoch 2, loss : 0.0242, val_loss : 0.2324, acc : 1.000, val_acc : 0.936\n",
      "Epoch 3, loss : 0.0184, val_loss : 0.1975, acc : 1.000, val_acc : 0.950\n",
      "Epoch 4, loss : 0.0293, val_loss : 0.2007, acc : 1.000, val_acc : 0.951\n",
      "Epoch 5, loss : 0.0129, val_loss : 0.1868, acc : 1.000, val_acc : 0.953\n",
      "Epoch 6, loss : 0.0140, val_loss : 0.2432, acc : 1.000, val_acc : 0.945\n",
      "Epoch 7, loss : 0.0463, val_loss : 0.3031, acc : 1.000, val_acc : 0.933\n",
      "Epoch 8, loss : 0.0097, val_loss : 0.2162, acc : 1.000, val_acc : 0.955\n",
      "Epoch 9, loss : 0.0121, val_loss : 0.2045, acc : 1.000, val_acc : 0.950\n",
      "test_acc : 0.956\n",
      "[3 6 4 ... 5 1 6]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いMNISTデータセットを多値分類する\n",
    "\"\"\"\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10\n",
    "stride = 1\n",
    "pad = 'VALID'\n",
    "ksize = [3, 3]\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, X_train.shape[1], X_train.shape[2], X_train.shape[3]])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n",
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([5, 5, 1, 4])),  # H, W, C, F\n",
    "        'w2': tf.Variable(tf.random_normal([3, 3, 4, 16])),\n",
    "        'w3': tf.Variable(tf.random_normal([64, 32])),\n",
    "        'w4': tf.Variable(tf.random_normal([32, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([1, 1, 1, 4])),\n",
    "        'b2': tf.Variable(tf.random_normal([1, 1, 1, 16])),\n",
    "        'b3': tf.Variable(tf.random_normal([32])),\n",
    "        'b4': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    layer_1 = tf.nn.conv2d(x, weights['w1'], stride, pad) + biases['b1']\n",
    "    layer_1 = tf.nn.max_pool2d(layer_1, ksize, ksize, pad)\n",
    "    layer_2 = tf.nn.conv2d(layer_1, weights['w2'], stride, pad) + biases['b2']\n",
    "    layer_2 = tf.nn.max_pool2d(layer_2, ksize, ksize, pad)\n",
    "    layer_2 = tf.layers.Flatten()(layer_2)\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    "    layer_output = tf.matmul(layer_3, weights['w4']) + biases['b4'] # tf.addと+は等価である\n",
    "    return layer_output\n",
    "\n",
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits), axis=0)\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(Y, axis=1), tf.argmax(tf.nn.softmax(logits), axis=1))\n",
    "# correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.nn.softmax(logits) - 0.5))\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            _, loss, acc = sess.run([train_op, loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "        total_loss /= n_samples\n",
    "        total_acc /= n_samples\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))\n",
    "    print(sess.run(tf.argmax(tf.nn.softmax(logits), 1), feed_dict={X: X_val, Y: y_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【keras版】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "im_rows, im_cols = 28, 28\n",
    "im_color = 1\n",
    "in_shape = (im_rows, im_cols, im_color)\n",
    "out_size = 10\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, im_rows, im_cols, im_color)\n",
    "X_train = X_train.astype('float64') / 255\n",
    "X_test = X_test.reshape(-1, im_rows, im_cols, im_color)\n",
    "X_test = X_test.astype('float64') / 255\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train.astype('float64'), 10)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test.astype('float64'), 10)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 99s 2ms/step - loss: 0.2547 - accuracy: 0.9226 - val_loss: 0.0588 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 100s 2ms/step - loss: 0.0900 - accuracy: 0.9746 - val_loss: 0.0450 - val_accuracy: 0.9856\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 98s 2ms/step - loss: 0.0670 - accuracy: 0.9804 - val_loss: 0.0401 - val_accuracy: 0.9868\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 97s 2ms/step - loss: 0.0577 - accuracy: 0.9833 - val_loss: 0.0383 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 97s 2ms/step - loss: 0.0518 - accuracy: 0.9852 - val_loss: 0.0364 - val_accuracy: 0.9899\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 98s 2ms/step - loss: 0.0484 - accuracy: 0.9868 - val_loss: 0.0355 - val_accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 99s 2ms/step - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.0348 - val_accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 103s 2ms/step - loss: 0.0423 - accuracy: 0.9872 - val_loss: 0.0378 - val_accuracy: 0.9901\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 102s 2ms/step - loss: 0.0422 - accuracy: 0.9883 - val_loss: 0.0347 - val_accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0415 - val_accuracy: 0.9893\n",
      "10000/10000 [==============================] - 3s 336us/step\n",
      "accuracy= 0.9894000291824341 loss= 0.03625896701642664\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-6fc90f23fd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# アーリーストッピングの設定\n",
    "# monitorに設定した要素が、patience回数、変化量min_dataを下回った場合にストップ\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0, patience=2)\n",
    "\n",
    "\n",
    "# モデル構築\n",
    "model = Sequential() # インスタンス\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=in_shape)) # 1層目、畳み込み\n",
    "model.add(Conv2D(64, (3,3), activation='relu')) # 2層目、畳み込み\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # 3層目、プーリング層\n",
    "model.add(Dropout(0.25)) # ドロップアウト、設定した割合で値を0にする(忘れる)\n",
    "model.add(Flatten()) # flatten、平滑化\n",
    "model.add(Dense(128, activation='relu')) # 全結合層\n",
    "model.add(Dropout(0.5)) # ドロップアウト\n",
    "model.add(Dense(out_size, activation='softmax')) # 全結合層、最終層\n",
    "\n",
    "#モデルコンパイル\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "hist = model.fit(X_train, y_train, batch_size=100, epochs=10, verbose=1, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# テストデータでテストしたスコアを出力\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"accuracy=\", score[1], 'loss=', score[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
